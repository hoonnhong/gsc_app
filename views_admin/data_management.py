import streamlit as st
import math
import pandas as pd
import time
from services.migration_service import MigrationService

def show():
    st.title("ğŸ’¾ ë°ì´í„° ê´€ë¦¬ (Data Management)")
    
    # íƒ­ êµ¬ì„± (í™•ì¥ì„± ê³ ë ¤)
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’° íšŒê³„ ìë£Œ", "ğŸ‘¥ ì¡°í•©ì› ìë£Œ", "ğŸ¥ í•œì˜ì› í™˜ì", "ğŸ’Š í•œì˜ì› íŒë§¤"])
    
    with tab1:
        _render_accounting_tab()
    
    with tab2:
        st.info("ğŸš§ ì¡°í•©ì› ìë£Œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„ ì¤‘")
        
    with tab3:
        st.info("ğŸš§ í•œì˜ì› í™˜ì ìë£Œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„ ì¤‘")
        
    with tab4:
        st.info("ğŸš§ í•œì˜ì› íŒë§¤ ìë£Œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„ ì¤‘")

def _render_accounting_tab():
    """íšŒê³„ ìë£Œ íƒ­ ë Œë”ë§"""
    st.markdown("### ğŸ“¥ íšŒê³„ ì—‘ì…€ ì—…ë¡œë“œ")
    st.caption("ê¸°ì¡´ ë°ì´í„°ì— ìƒˆë¡œìš´ ì—‘ì…€ íŒŒì¼ ë‚´ìš©ì„ **ì¶”ê°€(Append)** í•©ë‹ˆë‹¤. ì—…ë¡œë“œ í›„ ì¤‘ë³µ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # íŒŒì¼ ì—…ë¡œë“œ (Sidebarê°€ ì•„ë‹Œ ë©”ì¸ í™”ë©´ì— ë°°ì¹˜í•˜ì—¬ íƒ­ë³„ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€)
    uploaded_file = st.file_uploader("íšŒê³„ ì—‘ì…€ íŒŒì¼ (.xlsx)", type=['xlsx'], key="acc_uploader")
    
    if uploaded_file:
        # íŒŒì¼ ID ìƒì„± (ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€)
        file_id = f"{uploaded_file.name}_{uploaded_file.size}"
        
        # ë²„íŠ¼ì„ ëˆŒëŸ¬ì•¼ ì‹¤í–‰ë˜ë„ë¡ ë³€ê²½ (ì‹¤ìˆ˜ ë°©ì§€)
        if st.button("ğŸ”„ ë°ì´í„° ë³€í™˜ ë° ì €ì¥ ì‹œì‘", type="primary"):
            with st.spinner("ë°ì´í„° ì •ì œ ë° DB ë³€í™˜ ì¤‘..."):
                try:
                    count = MigrationService.process_accounting_data(uploaded_file)
                    st.success(f"âœ… ì²˜ë¦¬ ì™„ë£Œ! ì´ {count}ê±´ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.session_state['acc_last_update'] = file_id # ê°±ì‹  íŠ¸ë¦¬ê±°
                    st.session_state['show_duplicate_check'] = True # ì¤‘ë³µ í™•ì¸ ìë™ í™œì„±í™”
                except Exception as e:
                    st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    st.divider()

    # ì¤‘ë³µ ë°ì´í„° ê´€ë¦¬ (NEW)
    _render_duplicate_manager()
    
    st.divider()
    
    # ë°ì´í„° ì¡°íšŒ (Paging)
    _render_accounting_table()

def _render_duplicate_manager():
    """ì¤‘ë³µ ë°ì´í„° í™•ì¸ ë° ìˆ˜ì •"""
    st.markdown("### âš ï¸ ì¤‘ë³µ ë°ì´í„° ê´€ë¦¬")
    st.info("ğŸ’¡ **ì•ˆë‚´**: ì¤‘ë³µëœ ë°ì´í„° ì¤‘ í•˜ë‚˜ë¥¼ ì‚­ì œí•˜ì—¬ 1ê±´ë§Œ ë‚¨ê²Œ ë˜ë©´, ë” ì´ìƒ ì¤‘ë³µì´ ì•„ë‹ˆë¯€ë¡œ **ì´ ëª©ë¡ì—ì„œ ì‚¬ë¼ì§€ê³ ** ì „ì²´ ë°ì´í„° ëª©ë¡ì—ë§Œ ë‚¨ìŠµë‹ˆë‹¤.")
    
    col_dup_header, col_dup_btn = st.columns([8, 2])
    with col_dup_btn:
        if st.button("ğŸ”„ ëª©ë¡ ìƒˆë¡œê³ ì¹¨", key="refresh_dup"):
            st.rerun()
    
    # ì¤‘ë³µ í™•ì¸ ìë™ í¼ì¹˜ê¸° ë¡œì§
    default_expanded = st.session_state.get('show_duplicate_check', False)
    
    # ì‚­ì œ ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ (Rerun í›„)
    if 'dup_msg' in st.session_state:
        st.success(st.session_state['dup_msg'])
        del st.session_state['dup_msg']
    
    with st.expander("ì¤‘ë³µ ì˜ì‹¬ ë°ì´í„° í™•ì¸í•˜ê¸° (ë™ì¼í•œ ë‚ ì§œ, ëª©, ì„¸ëª©, ì ìš”, ê¸ˆì•¡)", expanded=default_expanded):
        df_dup = MigrationService.get_duplicates()
        
        if df_dup.empty:
            st.success("ì¤‘ë³µëœ ë°ì´í„°ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. âœ…")
        else:
            st.warning(f"ì´ {len(df_dup)}ê±´ì˜ ì¤‘ë³µ ì˜ì‹¬ ë°ì´í„°ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.markdown("ì•„ë˜ í…Œì´ë¸”ì—ì„œ ë°ì´í„°ë¥¼ ì§ì ‘ **ìˆ˜ì •**í•˜ê±°ë‚˜ **ì‚­ì œ**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # í¸ì§‘ìš© ë°ì´í„°í”„ë ˆì„ (IDëŠ” ìˆ˜ì • ë¶ˆê°€)
            column_map = {
                'id': 'ID',
                'type': 'ìˆ˜ì…/ì§€ì¶œ', 'gwan': 'ê´€', 'hang': 'í•­', 'mok': 'ëª©', 'semok': 'ì„¸ëª©',
                'detail_1': 'ìƒì„¸1', 'detail_2': 'ìƒì„¸2', 'detail_3': 'ìƒì„¸3', 'detail_4': 'ìƒì„¸4',
                'amount': 'ê¸ˆì•¡', 'account_name': 'ê³„ì¢Œëª…', 'reg_date': 'ë“±ê¸°ì¼'
            }
            
            edited_df = st.data_editor(
                df_dup.rename(columns=column_map),
                use_container_width=True,
                hide_index=True,
                num_rows="dynamic",

                key=f"dup_editor_{len(df_dup)}", # ë°ì´í„° ê°œìˆ˜ê°€ ë°”ë€Œë©´ ì»´í¬ë„ŒíŠ¸ ê°•ì œ ë¦¬ë Œë”ë§
                disabled=["ID"] # ID ìˆ˜ì • ë°©ì§€
            )
            
            # ë³€ê²½ ì‚¬í•­ ì ìš© (Diff check is tricky with data_editor key state, 
            # but st.data_editor returns the current state.
            # To handle real DB updates, we need to compare or use on_change callback.
            # Streamlit data_editor handles state internally. 
            # We need a proper commit button or detect changes.)
            
            # st.data_editor's output `edited_df` is just the dataframe state.
            # It doesn't tell us WHAT changed easily unless we compare.
            # BUT, data_editor has `num_rows="dynamic"` which allows add/delete.
            # Actually, `experimental_data_editor` changed to `data_editor`.
            # We can use `on_change` with `st.session_state`.
            
    # NOTE: Real-time DB update with data_editor is complex in standard Streamlit pattern without Session State hacking.
    # Simplified approach: "Check inconsistencies" -> Show table -> "User manages ID-based actions separately?"
    # Better: Use `st.data_editor` return value and a "Save Changes" button.
    # But `data_editor` returns the final dataframe. We need to know what to UPDATE/DELETE.
    
    # Revised Approach for Simplicity & Stability:
    # Just list them. Provide 'Delete' button per row? No, too many rows.
    # Provide a simple "Delete All Duplicates (Keep One)"? Dangerous.
    # Let's use the layout requested: "Color display -> Modify/Delete".
    
            # st.data_editorì—ì„œ ì‚­ì œ/ìˆ˜ì •ëœ ë‚´ìš© ì²˜ë¦¬
            # deleted_rowsëŠ” session_stateì˜ editor keyì— ì €ì¥ë¨
            if f"dup_editor_{len(df_dup)}" in st.session_state:
                editor_state = st.session_state[f"dup_editor_{len(df_dup)}"]
                
                # ì‚­ì œëœ í–‰ ì²˜ë¦¬
                deleted_rows = editor_state.get("deleted_rows", [])
                if deleted_rows:
                    # ì‚­ì œëœ í–‰ì˜ ì¸ë±ìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì—ì„œ IDë¥¼ ì°¾ìŒ
                    # df_dupëŠ” 0ë¶€í„° ì‹œì‘í•˜ëŠ” RangeIndexë¥¼ ê°€ì§€ê³  ìˆë‹¤ê³  ê°€ì •í•˜ë©´ ì•ˆë¨.
                    # data_editorì˜ deleted_rows ì¸ë±ìŠ¤ëŠ” í‘œì‹œëœ dfì˜ í–‰ ë²ˆí˜¸ì„.
                    
                    # ì‚­ì œëœ í–‰ì˜ ID ìˆ˜ì§‘
                    deleted_ids = []
                    for row_idx in deleted_rows:
                        # df_dupì˜ í•´ë‹¹ row_idx í–‰ì„ ê°€ì ¸ì˜´
                        deleted_id = df_dup.iloc[row_idx]['id']
                        deleted_ids.append(int(deleted_id))
                    
                    if deleted_ids:
                        for del_id in deleted_ids:
                            MigrationService.delete_transaction(del_id)
                        
                        st.session_state['dup_msg'] = f"ì´ {len(deleted_ids)}ê±´ ì‚­ì œ ì™„ë£Œ. (ì‚¬ë¼ì§„ ë°ì´í„°ê°€ DBì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤)"
                        time.sleep(0.1) # DB ë°˜ì˜ ëŒ€ê¸°
                        st.rerun()

                # ìˆ˜ì •ëœ í–‰ ì²˜ë¦¬ (ì¼ê´„ ì ìš© ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰)
                edited_rows = editor_state.get("edited_rows", {})
                
                # ë²„íŠ¼ì„ í†µí•´ ì¼ê´„ ì ìš©
                col_btn_1, col_btn_2 = st.columns([8, 2])
                with col_btn_2:
                    apply_btn = st.button("âœï¸ ìˆ˜ì • ì‚¬í•­ ì¼ê´„ ì ìš©", key="apply_edits", disabled=not edited_rows, type="primary")

                if apply_btn and edited_rows:
                    # edited_rowsëŠ” {row_idx: {col_name: new_value}} í˜•íƒœ
                    
                    # ì—­ë°©í–¥ ì»¬ëŸ¼ ë§¤í•‘ (UI -> DB)
                    reverse_column_map = {v: k for k, v in column_map.items()}
                    
                    updated_count = 0
                    for row_idx, changes in edited_rows.items():
                        # ì‹¤ì œ ID ì¡°íšŒ
                        row_id = int(df_dup.iloc[int(row_idx)]['id'])
                        
                        # ë³€ê²½ëœ ë°ì´í„° DB ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€í™˜
                        db_changes = {}
                        for ui_col, new_val in changes.items():
                            if ui_col in reverse_column_map:
                                db_col = reverse_column_map[ui_col]
                                db_changes[db_col] = new_val
                        
                        if db_changes:
                            MigrationService.update_transaction(row_id, db_changes)
                            updated_count += 1
                    
                    if updated_count > 0:
                        st.session_state['dup_msg'] = f"ì´ {updated_count}ê±´ ìˆ˜ì • ì™„ë£Œ."
                        time.sleep(0.1)
                        st.rerun()

    # (ì´ì „ ë¡œì§ ì œê±°)
    # if not df_dup.empty: ...

    st.markdown("#### ğŸš¨ ìœ„í—˜ ì§€ì—­ (Danger Zone)")
    with st.expander("ğŸ—‘ï¸ ì „ì²´ ë°ì´í„° ì‚­ì œ (ì£¼ì˜!)"):
        st.warning("âš ï¸ ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  íšŒê³„ ë°ì´í„°ê°€ ì˜êµ¬ì ìœ¼ë¡œ ì‚­ì œë©ë‹ˆë‹¤.")
        if st.checkbox("ë°ì´í„°ë¥¼ ëª¨ë‘ ì‚­ì œí•˜ëŠ” ê²ƒì— ë™ì˜í•©ë‹ˆë‹¤.", key="agree_delete_all"):
            if st.button("ğŸ”¥ ì „ì²´ ë°ì´í„° ì¦‰ì‹œ ì‚­ì œ", type="primary"):
                try:
                    MigrationService.delete_all_transactions()
                    st.success("ëª¨ë“  ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # (ì´ì „ ë¡œì§ ì œê±°)
    # if not df_dup.empty: ...

def _render_accounting_table():
    """íšŒê³„ ë°ì´í„° í˜ì´ì§• ì¡°íšŒ í…Œì´ë¸”"""
    st.markdown("### ğŸ“‹ ì €ì¥ëœ ë°ì´í„° í™•ì¸")
    
    if 'acc_page' not in st.session_state:
        st.session_state['acc_page'] = 1
        
    # ë°ì´í„° ê±´ìˆ˜ ì¡°íšŒ
    total_rows = MigrationService.get_accounting_summary()
    ROWS_PER_PAGE = 20
    
    if total_rows == 0:
        st.info("ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    total_pages = math.ceil(total_rows / ROWS_PER_PAGE)
    
    # í˜ì´ì§€ ë³´ì •
    if st.session_state['acc_page'] > total_pages: st.session_state['acc_page'] = total_pages
    if st.session_state['acc_page'] < 1: st.session_state['acc_page'] = 1
    
    current_page = st.session_state['acc_page']
    
    # í˜ì´ì§• ì»¨íŠ¸ë¡¤ (TOP)
    col_l, col_r = st.columns([8, 2])
    with col_l:
        st.markdown(f"**Total: {total_rows}ê±´**")
    with col_r:
        st.markdown(f"**Page {current_page} / {total_pages}**")

    # ë°ì´í„° ì¡°íšŒ
    df = MigrationService.get_accounting_data(limit=ROWS_PER_PAGE, offset=(current_page-1)*ROWS_PER_PAGE)
    
    # ì»¬ëŸ¼ ë§¤í•‘ Display
    column_map = {
        'type': 'ìˆ˜ì…/ì§€ì¶œ', 'gwan': 'ê´€', 'hang': 'í•­', 'mok': 'ëª©', 'semok': 'ì„¸ëª©',
        'detail_1': 'ìƒì„¸1', 'detail_2': 'ìƒì„¸2', 'detail_3': 'ìƒì„¸3', 'detail_4': 'ìƒì„¸4',
        'amount': 'ê¸ˆì•¡', 'account_name': 'ê³„ì¢Œëª…', 'reg_date': 'ë“±ê¸°ì¼'
    }
    
    st.dataframe(
        df.rename(columns=column_map),
        use_container_width=True,
        hide_index=True,
        column_config={
            "ê¸ˆì•¡": st.column_config.NumberColumn(format="%dì›")
        }
    )
    
    # í˜ì´ì§• ì»¨íŠ¸ë¡¤ (Bottom)
    c1, c2, c3, c4, c5 = st.columns([1, 1, 4, 1, 1])
    with c2:
        if st.button("â—€ ì´ì „", key="acc_prev", disabled=(current_page <= 1)):
            st.session_state['acc_page'] -= 1
            st.rerun()
    with c4:
        if st.button("ë‹¤ìŒ â–¶", key="acc_next", disabled=(current_page >= total_pages)):
            st.session_state['acc_page'] += 1
            st.rerun()
